{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "69b395a7",
   "metadata": {},
   "source": [
    "# Solving MNIST & CIFAR-10 Using Convolution Layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fce633c0",
   "metadata": {},
   "source": [
    "### Goal:\n",
    "Design a simple ANN for handwritten digit classification where the model will be trained, validated, and tested on: MNIST and CIFAR-10\n",
    "\n",
    "### Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d69f8f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# Model / data parameters\n",
    "num_classes = 10\n",
    "input_shape = (28, 28, 1)\n",
    "\n",
    "# the data, split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
    "\n",
    "# Scale images to the [0, 1] range\n",
    "x_train = x_train.astype(\"float32\") / 255\n",
    "x_test = x_test.astype(\"float32\") / 255\n",
    "# Make sure images have shape (28, 28, 1)\n",
    "x_train = np.expand_dims(x_train, -1)\n",
    "x_test = np.expand_dims(x_test, -1)\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eae15e56",
   "metadata": {},
   "source": [
    "### Keras Sequential API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "99dedc41",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_12 (Conv2D)          (None, 26, 26, 32)        320       \n",
      "                                                                 \n",
      " max_pooling2d_12 (MaxPoolin  (None, 13, 13, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_13 (Conv2D)          (None, 11, 11, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_13 (MaxPoolin  (None, 5, 5, 64)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_6 (Flatten)         (None, 1600)              0         \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 1600)              0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 10)                16010     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 34,826\n",
      "Trainable params: 34,826\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\\nmodel.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.1, verbose=0)\\n\\n# Model Evaluation\\nscore = model.evaluate(x_test, y_test, verbose=0)\\nprint(\"Test loss:\", score[0])\\nprint(\"Test accuracy:\", score[1])'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Hyperparameters\n",
    "epochs = 15\n",
    "batch_size = 128\n",
    "\n",
    "# Build and Train the Model\n",
    "model = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=input_shape),\n",
    "        layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Flatten(),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(num_classes, activation=\"softmax\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "model.summary()\n",
    "\"\"\"model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.1, verbose=0)\n",
    "\n",
    "# Model Evaluation\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print(\"Test loss:\", score[0])\n",
    "print(\"Test accuracy:\", score[1])\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb687855",
   "metadata": {},
   "source": [
    "### Keras Functional API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "23d67b57",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"mnist_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_6 (InputLayer)        [(None, 28, 28, 1)]       0         \n",
      "                                                                 \n",
      " conv2d_10 (Conv2D)          (None, 26, 26, 32)        320       \n",
      "                                                                 \n",
      " max_pooling2d_10 (MaxPoolin  (None, 13, 13, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_11 (Conv2D)          (None, 11, 11, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_11 (MaxPoolin  (None, 5, 5, 64)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_5 (Flatten)         (None, 1600)              0         \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 1600)              0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 10)                16010     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 34,826\n",
      "Trainable params: 34,826\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\\nmodel.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.1, verbose=0)\\n\\n# Model Evaluation\\nscore = model.evaluate(x_test, y_test, verbose=0)\\nprint(\"Test loss:\", score[0])\\nprint(\"Test accuracy:\", score[1])'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Hyperparameters\n",
    "epochs = 15\n",
    "batch_size = 128\n",
    "\n",
    "\n",
    "inputs = keras.Input(shape=input_shape)\n",
    "x = layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\")(inputs)\n",
    "x = layers.MaxPooling2D(pool_size=(2, 2))(x)\n",
    "x = layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\")(x)\n",
    "x = layers.MaxPooling2D(pool_size=(2, 2))(x)\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "output = layers.Dense(num_classes, activation=\"softmax\")(x)\n",
    "\n",
    "# Build and Train the Model\n",
    "model = keras.Model(inputs=inputs, outputs=output, name=\"mnist_model\")\n",
    "\n",
    "model.summary()\n",
    "\"\"\"model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.1, verbose=0)\n",
    "\n",
    "# Model Evaluation\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print(\"Test loss:\", score[0])\n",
    "print(\"Test accuracy:\", score[1])\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8d1ff20",
   "metadata": {},
   "source": [
    "# Convolution Layer (From Scratch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "107e411e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class Convolution2D(layers.Layer):\n",
    "    \"\"\"2D convolution layer (e.g. spatial convolution over images).\n",
    "\n",
    "    This layer creates a convolution kernel that is convolved with the layer input to produce a tensor of outputs. If `use_bias` \n",
    "    is True, a bias vector is created and added to the outputs. Finally, if `activation` is not `None`, it is applied to the \n",
    "    outputs as well.\n",
    "    \"\"\"\n",
    "    def __init__(self, \n",
    "                 num_filters, \n",
    "                 kernel_size,\n",
    "                 strides=(1, 1),\n",
    "                 padding=\"valid\",\n",
    "                 data_format=None,\n",
    "                 dilation_rate=(1, 1),\n",
    "                 groups=1,\n",
    "                 activation=None,\n",
    "                 use_bias=True,\n",
    "                 kernel_initializer=\"glorot_uniform\",\n",
    "                 bias_initializer=\"zeros\",\n",
    "                 kernel_regularizer=None,\n",
    "                 bias_regularizer=None,\n",
    "                 activity_regularizer=None):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        name : str\n",
    "            The name of the animal\n",
    "        sound : str\n",
    "            The sound the animal makes\n",
    "        num_legs : int, optional\n",
    "            The number of legs the animal (default is 4)\n",
    "            \n",
    "        num_filters : int \n",
    "            The dimensionality of the output space (i.e. the number of output filters in the convolution).\n",
    "        kernel_size : int | tuple/list of 2 integers\n",
    "            Specifying the height and width of the 2D convolution window. Can be a single integer to specify the same value for \n",
    "            all spatial dimensions.\n",
    "        strides : int | or tuple/list of 2 integers\n",
    "            Specifying the strides of the convolution along the height and width. Can be a single integer to specify the same \n",
    "            value for all spatial dimensions. Specifying any stride value != 1 is incompatible with specifying any dilation_rate \n",
    "            value != 1.\n",
    "        padding : one of \"valid\" or \"same\" (case-insensitive). \n",
    "            \"valid\" means no padding. \"same\" results in padding with zeros evenly to the left/right or up/down of the input. \n",
    "            When padding=\"same\" and strides=1, the output has the same size as the input.\n",
    "        data_format : str\n",
    "            one of channels_last (default) or channels_first. The ordering of the dimensions in the inputs. channels_last \n",
    "            corresponds to inputs with shape (batch_size, height, width, channels) while channels_first corresponds to inputs \n",
    "            with shape (batch_size, channels, height, width). It defaults to the image_data_format value found in your Keras \n",
    "            config file at ~/.keras/keras.json. If you never set it, then it will be channels_last.\n",
    "        dilation_rate : int | tuple/list of 2 ints\n",
    "            Specifying the dilation rate to use for dilated convolution. Can be a single integer to specify the same value for all \n",
    "            spatial dimensions. Currently, specifying any dilation_rate value != 1 is incompatible with specifying any stride \n",
    "            value != 1.\n",
    "        groups : A positive int \n",
    "            Specifying the number of groups in which the input is split along the channel axis. Each group is convolved separately \n",
    "            with filters / groups filters. The output is the concatenation of all the groups results along the channel axis. Input \n",
    "            channels and filters must both be divisible by groups.\n",
    "        activation : callable\n",
    "            Activation function to use. If you don't specify anything, no activation is applied.\n",
    "        use_bias : bool \n",
    "            Whether the layer uses a bias vector.\n",
    "        kernel_initializer : tf.Variable\n",
    "            Initializer for the kernel weights matrix. Defaults to 'uniform'.\n",
    "        bias_initializer : tf.Variable\n",
    "            Initializer for the bias vector. Defaults to 'zeros'.\n",
    "        kernel_regularizer : callable\n",
    "            Regularizer function applied to the kernel weights matrix.\n",
    "        bias_regularizer : callable\n",
    "            Regularizer function applied to the bias vector.\n",
    "        activity_regularizer : callable\n",
    "            Regularizer function applied to the output of the layer (its \"activation\").\n",
    "        \"\"\"\n",
    "        super(Convolution2D, self).__init__()\n",
    "        # TODO make kernel and bias initializable\n",
    "        self.num_filters = num_filters\n",
    "        kernel_size,\n",
    "        strides=(1, 1),\n",
    "        padding=\"valid\",\n",
    "        data_format=None,\n",
    "        dilation_rate=(1, 1),\n",
    "        groups=1,\n",
    "        activation=None,\n",
    "        use_bias=True,\n",
    "        kernel_initializer=\"glorot_uniform\",\n",
    "        bias_initializer=\"zeros\",\n",
    "        kernel_regularizer=None,\n",
    "        bias_regularizer=None,\n",
    "        activity_regularizer=None\n",
    "        \n",
    "        \n",
    "        \n",
    "        def build(self, input_shape):\n",
    "        self.w = self.add_weight(\n",
    "            shape=(input_shape[-1], self.units),\n",
    "            initializer=\"random_normal\",\n",
    "            trainable=True,\n",
    "        )\n",
    "        self.b = self.add_weight(\n",
    "            shape=(self.units,), initializer=\"random_normal\", trainable=True\n",
    "        )\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
